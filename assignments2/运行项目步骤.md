# 3-1部分
## 3-1基本环境的安装：
```linux
# 安装基本环境
cd {项目总目录}
conda create -n val_base python==3.8    # 版本不能太高，否则可能无法安装Pillow
conda activate val_base
# 安装基本依赖，为了避免安装Pillow报错，首先用conda安装好
conda install pillow
# 然后从requirements.txt安装其他依赖
pip install -r requirements.txt
```

# 3-2部分
## 3-2B环境安装
```linux
# 安装基本环境
cd {项目总目录}/mml
conda create -n val_32 python==3.10 
conda activate val_32
# 安装基本依赖，为了避免安装Pillow报错，首先用conda安装好
conda install pillow
pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu118
# 然后从requirements.txt安装其他依赖
pip install -r requirements.txt
```

## 3-2B训练
首先进入`{项目总目录}`(即本文件夹根目录)，然后运行：
```linux
export PYTHONPATH=./:$PYTHONPATH
```

### 3-2B训练CLIP+GPT-2(Large)脚本
```linux
cd {项目总目录}/mml
python training.py -S L -C CLIP_GPT.pth
```

### 3-2B训练CLIP+Qwen2.5-0.5B脚本
```linux
cd {项目总目录}/mml
python qwen_training.py -C CLIP_Qwen.pth
```

### 3-2B评估CLIP+GPT-2(Large)脚本：
```linux
cd {项目总目录}/mml

# 运行evaluate.py，评估CLIP+GPT-2(Large)模型，需要运行12425张images
python evaluate.py -C epoch_96.pt -S L -I ./datasets/train2014 -R ./result
```

### 3-2B评估CLIP+Qwen脚本：
```linux
cd {项目总目录}/mml

# 运行evaluate.py，评估CLIP+GPT-2(Large)模型，需要运行12425张images
python qwen_evaluate.py -C epoch_96.pt -S L -I ./datasets/train2014 -R ./result
```

